{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "5_1_단어 단위 생성.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNeOxVi1Diq78EYd7lpwDSk",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/psst54/startTensorflow/blob/master/weekly/5_1_%EB%8B%A8%EC%96%B4_%EB%8B%A8%EC%9C%84_%EC%83%9D%EC%84%B1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CubcuYPgAN3g"
      },
      "source": [
        "https://github.com/wikibook/tf2/blob/master/Chapter7.ipynb 를 따름"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tEKbrHVP-sjH"
      },
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7QwkqUZI_1nk"
      },
      "source": [
        "국사편찬위원회에서 제공하는 조선왕조실록 데이터를 다운받는다"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VtjdkRa_8IIj",
        "outputId": "2a42fe74-2f7f-4959-a000-05d387fde44c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 125
        }
      },
      "source": [
        "path_to_file = tf.keras.utils.get_file('input.txt', 'http://bit.ly/2Mc3SOV')\n",
        "\n",
        "train_text = open(path_to_file, 'rb').read().decode(encoding='utf-8')\n",
        "\n",
        "print('Length of text: {} characters'.format(len(train_text)))\n",
        "print()\n",
        "\n",
        "print(train_text[:100])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from http://bit.ly/2Mc3SOV\n",
            "62013440/62012502 [==============================] - 1s 0us/step\n",
            "Length of text: 26265493 characters\n",
            "\n",
            "﻿태조 이성계 선대의 가계. 목조 이안사가 전주에서 삼척·의주를 거쳐 알동에 정착하다 \n",
            "태조 강헌 지인 계운 성문 신무 대왕(太祖康獻至仁啓運聖文神武大王)의 성은 이씨(李氏)요, 휘\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NXwOiqIrBrFY"
      },
      "source": [
        "한글과 개행 문자만 남도록 처리하는 과정이다.\n",
        "\n",
        "개행문자를 기준으로 train_text를 나누고, 각 문장을 clean_str() 함수의 인자로 넘겨준다. 그리고 각 문장을 띄어쓰기 단위로 자른 다음 개행문자와 함께 train_text_X에 저장한다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FNgU51tF-zaS",
        "outputId": "a820e80f-c531-42f2-cf38-4fff1d708f4b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "import re\n",
        "# From https://github.com/yoonkim/CNN_sentence/blob/master/process_data.py\n",
        "def clean_str(string):    \n",
        "    string = re.sub(r\"[^가-힣A-Za-z0-9(),!?\\'\\`]\", \" \", string)\n",
        "    string = re.sub(r\"\\'ll\", \" \\'ll\", string)\n",
        "    string = re.sub(r\",\", \" , \", string)\n",
        "    string = re.sub(r\"!\", \" ! \", string)\n",
        "    string = re.sub(r\"\\(\", \"\", string)\n",
        "    string = re.sub(r\"\\)\", \"\", string)\n",
        "    string = re.sub(r\"\\?\", \" \\? \", string)\n",
        "    string = re.sub(r\"\\s{2,}\", \" \", string)\n",
        "    string = re.sub(r\"\\'{2,}\", \"\\'\", string)\n",
        "    string = re.sub(r\"\\'\", \"\", string)\n",
        "\n",
        "    return string\n",
        "    \n",
        "\n",
        "train_text = train_text.split('\\n')\n",
        "train_text = [clean_str(sentence) for sentence in train_text]\n",
        "train_text_X = []\n",
        "\n",
        "for sentence in train_text:\n",
        "    train_text_X.extend(sentence.split(' '))\n",
        "    train_text_X.append('\\n')\n",
        "\n",
        "train_text_X = [word for word in train_text_X if word != '']\n",
        "\n",
        "print(train_text_X[:20])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['태조', '이성계', '선대의', '가계', '목조', '이안사가', '전주에서', '삼척', '의주를', '거쳐', '알동에', '정착하다', '\\n', '태조', '강헌', '지인', '계운', '성문', '신무', '대왕']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_yHHA87YDuNs"
      },
      "source": [
        "vocab에는 train_text_X에 저장된 모든 단어들이 중복 없이 정렬되어 있다. 맨 마지막 원소로 'UNK' 토큰을 넣고 word2idx, idx2word"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Drh4HQmeAK6x",
        "outputId": "dafe6883-56a1-44ae-d303-233ff2e683c9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 287
        }
      },
      "source": [
        "vocab = sorted(set(train_text_X))\n",
        "vocab.append('UNK')\n",
        "# UNK는 이후 임의의 문장을 입력할 때 텍스트에 미리 준비되어 있지 않은 단어를 사용할 경우에 대한 토큰\n",
        "print('{} unique words'.format(len(vocab)))\n",
        "\n",
        "word2idx = {u:i for i, u in enumerate(vocab)}\n",
        "idx2word = np.array(vocab)\n",
        "\n",
        "text_as_int = np.array([word2idx[c] for c in train_text_X])\n",
        "\n",
        "print('{')\n",
        "for word,_ in zip(word2idx, range(10)):\n",
        "    print(' {:4s}: {:3d},'.format(repr(word), word2idx[word]))\n",
        "print(' ...\\n}');\n",
        "\n",
        "print('index of UNK: {}'.format(word2idx['UNK']))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "332640 unique words\n",
            "{\n",
            " '\\n':   0,\n",
            " '!' :   1,\n",
            " ',' :   2,\n",
            " '000명으로':   3,\n",
            " '001':   4,\n",
            " '002':   5,\n",
            " '003':   6,\n",
            " '004':   7,\n",
            " '005':   8,\n",
            " '006':   9,\n",
            " ...\n",
            "}\n",
            "index of UNK: 332639\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cz2MfCK4FEvx"
      },
      "source": [
        "train_text_X의 단어들의 정렬 순서에 해당하는 값을 text_as_int에 저장한다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NN-cz-tEGFun",
        "outputId": "d0f39a41-b4b3-46a7-c819-1cb7957d7a2b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        }
      },
      "source": [
        "print(train_text_X[:20])\n",
        "print(text_as_int[:20])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['태조', '이성계', '선대의', '가계', '목조', '이안사가', '전주에서', '삼척', '의주를', '거쳐', '알동에', '정착하다', '\\n', '태조', '강헌', '지인', '계운', '성문', '신무', '대왕']\n",
            "[299305 229634 161443  17430 111029 230292 251081 155087 225462  29027\n",
            " 190295 256129      0 299305  25624 273553  36147 163996 180466  84413]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ofgGUEOkHwYM"
      },
      "source": [
        "25 단어가 주어지면 다음 단어를 예측하도록 신경망을 학습시키고자 한다. seq_length에는 25를 저장하고, examples_per_epoch에는 전체 text의 길이를 seq_length로 나눈 몫을 저장한다.\n",
        "\n",
        "sentence_dataset은 text_as_int의 각 단어들을 Dataset 형태로 저장한 것이다. 이를 seq_length(25 입력 + 1 출력)만큼씩 나누어 저장한다. 나머지는 drop_remainder 옵션으로 버릴 수 있다.\n",
        "\n",
        "dataset에 대한 자세한 내용은\n",
        "https://www.tensorflow.org/api_docs/python/tf/data/Dataset\n",
        "참고\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "erTSBoKGGc2T",
        "outputId": "2aec0454-3393-4590-8699-8b007cac0455",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 107
        }
      },
      "source": [
        "seq_length = 25\n",
        "# seq_length가 25이면 25개의 단어가 주어졌을 때 다음 단어를 예측하도록 할 수 있음.\n",
        "examples_per_epoch = len(text_as_int) // seq_length\n",
        "\n",
        "sentence_dataset = tf.data.Dataset.from_tensor_slices(text_as_int)\n",
        "sentence_dataset = sentence_dataset.batch(seq_length+1, drop_remainder=True)\n",
        "# batch()함수의 인자로는 반환되는 데이터의 숫자를 지정함. \n",
        "# 첫 25단어는 입력이고 마지막 한 단어는 정답.\n",
        "# drop_remainder=True로 남는 부분은 버림.\n",
        "\n",
        "for item in sentence_dataset.take(1):\n",
        "    print(idx2word[item.numpy()])\n",
        "    print(item.numpy())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['태조' '이성계' '선대의' '가계' '목조' '이안사가' '전주에서' '삼척' '의주를' '거쳐' '알동에' '정착하다'\n",
            " '\\n' '태조' '강헌' '지인' '계운' '성문' '신무' '대왕' '의' '성은' '이씨' '요' ',' '휘']\n",
            "[299305 229634 161443  17430 111029 230292 251081 155087 225462  29027\n",
            " 190295 256129      0 299305  25624 273553  36147 163996 180466  84413\n",
            " 224182 164549 230248 210912      2 330313]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fUc83pylIAvp"
      },
      "source": [
        "take() : https://www.tensorflow.org/api_docs/python/tf/data/Dataset#take\n",
        "\n",
        "from_tensor_slices() : https://www.tensorflow.org/api_docs/python/tf/data/Dataset#from_tensor_slices\n",
        "\n",
        "\n",
        "26개의 단어를 다시 25개의 입력, 1개의 정답으로 나누어준다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0KLFXuPnKFJS"
      },
      "source": [
        "def split_input_target(chunk):\n",
        "    return [chunk[:-1], chunk[-1]]\n",
        "# 26개의 단어를 25개, 1개로 잘라주는 함수.\n",
        "\n",
        "train_dataset = sentence_dataset.map(split_input_target)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FkxOjXahQVOE",
        "outputId": "e0a07296-fd50-485a-e1e7-2eb49ca5a0e2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 395
        }
      },
      "source": [
        "# 25개의 입력과 정답을 출력함(3번)\n",
        "\n",
        "for x, y in train_dataset.take(3):\n",
        "    print(idx2word[x.numpy()])\n",
        "    print(x.numpy())\n",
        "    print(idx2word[y.numpy()])\n",
        "    print(y.numpy())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['태조' '이성계' '선대의' '가계' '목조' '이안사가' '전주에서' '삼척' '의주를' '거쳐' '알동에' '정착하다'\n",
            " '\\n' '태조' '강헌' '지인' '계운' '성문' '신무' '대왕' '의' '성은' '이씨' '요' ',']\n",
            "[299305 229634 161443  17430 111029 230292 251081 155087 225462  29027\n",
            " 190295 256129      0 299305  25624 273553  36147 163996 180466  84413\n",
            " 224182 164549 230248 210912      2]\n",
            "휘\n",
            "330313\n",
            "['는' '단' '이요' ',' '자' '는' '군진' '이다' '그전의' '휘' '는' '이성계' '요' ',' '호' '는'\n",
            " '송헌' '이다' '전주' '의' '대성' '이다' '사공' '휘' '이한']\n",
            "[ 77850  80105 230992      2 240316  77850  49621 226910  53932 330313\n",
            "  77850 229634 210912      2 322525  77850 170794 226910 251070 224182\n",
            "  83973 226910 147977 330313 233123]\n",
            "이\n",
            "225845\n",
            "['신라' '에' '벼슬하여' '태종왕' '001' '의' '10대' '손자인' '군윤' '김은의' '의' '딸에게' '장가들어'\n",
            " '시중' '휘' '이자연' '을' '낳았다' '시중이' '복야' '휘' '이천상' '을' '낳고' ',']\n",
            "[180269 197963 131090 299389      4 224182    359 169777  49369  62515\n",
            " 224182  98407 244180 178763 330313 231753 223046  70716 178782 136380\n",
            " 330313 232680 223046  70689      2]\n",
            "복야가\n",
            "136381\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mR-OgJaDPEb6"
      },
      "source": [
        "BATCH_SIZE = 512\n",
        "steps_per_epoch = examples_per_epoch // BATCH_SIZE\n",
        "BUFFER_SIZE = 10000\n",
        "\n",
        "train_dataset = train_dataset.shuffle(BUFFER_SIZE).batch(BATCH_SIZE, drop_remainder=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yQv7JiTvNzxb",
        "outputId": "79e37d8c-daa1-4702-e5ba-23f188b50af4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 341
        }
      },
      "source": [
        "total_words = len(vocab)\n",
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Embedding(total_words, 100, input_length=seq_length),\n",
        "    tf.keras.layers.LSTM(units=100, return_sequences=True),\n",
        "    tf.keras.layers.Dropout(0.2),\n",
        "    tf.keras.layers.LSTM(units=100),\n",
        "    tf.keras.layers.Dense(total_words, activation='softmax')\n",
        "])\n",
        "\n",
        "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding (Embedding)        (None, 25, 100)           33264000  \n",
            "_________________________________________________________________\n",
            "lstm (LSTM)                  (None, 25, 100)           80400     \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 25, 100)           0         \n",
            "_________________________________________________________________\n",
            "lstm_1 (LSTM)                (None, 100)               80400     \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 332640)            33596640  \n",
            "=================================================================\n",
            "Total params: 67,021,440\n",
            "Trainable params: 67,021,440\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "svxpznSsQJVh"
      },
      "source": [
        "testmodel 함수는 5번째 학습마다 결과를 출력한다. 매 시도마다 train_text[0](\"태조 이성계 선대의 가계 목조 이안사가 전주에서 삼척 의주를 거쳐 알동에 정착하다\") 이후의 100단어를 출력한다.\n",
        "\n",
        "predict_classes는 test_sentence 다음에 올 단어의 인덱스를 반환하고, idx2word 리스트를 통해 다음 단어를 test_sentence에 연결한다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pikuJF3yOmrR",
        "outputId": "8e2e94e6-babb-445d-fb7b-14900afb7755",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "def testmodel(epoch, logs):\n",
        "    if epoch % 5 != 0 and epoch != 49:\n",
        "        return\n",
        "    test_sentence = train_text[0]\n",
        "\n",
        "    next_words = 100\n",
        "    for _ in range(next_words):\n",
        "        test_text_X = test_sentence.split(' ')[-seq_length:]\n",
        "        test_text_X = np.array([word2idx[c] if c in word2idx else word2idx['UNK'] for c in test_text_X])\n",
        "        test_text_X = pad_sequences([test_text_X], maxlen=seq_length, padding='pre', value=word2idx['UNK'])\n",
        "\n",
        "        output_idx = model.predict_classes(test_text_X)\n",
        "        test_sentence += ' ' + idx2word[output_idx[0]]\n",
        "    \n",
        "    print()\n",
        "    print(test_sentence)\n",
        "    print()\n",
        "\n",
        "testmodelcb = tf.keras.callbacks.LambdaCallback(on_epoch_end=testmodel)\n",
        "\n",
        "history = model.fit(train_dataset.repeat(), epochs=50, steps_per_epoch=steps_per_epoch, callbacks=[testmodelcb], verbose=2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "WARNING:tensorflow:From <ipython-input-11-9bc7b3ede408>:14: Sequential.predict_classes (from tensorflow.python.keras.engine.sequential) is deprecated and will be removed after 2021-01-01.\n",
            "Instructions for updating:\n",
            "Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
            "\n",
            " 태조 이성계 선대의 가계 목조 이안사가 전주에서 삼척 의주를 거쳐 알동에 정착하다  , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , ,\n",
            "\n",
            "533/533 - 411s - loss: 9.3794 - accuracy: 0.0721\n",
            "Epoch 2/50\n",
            "533/533 - 405s - loss: 8.3608 - accuracy: 0.0740\n",
            "Epoch 3/50\n",
            "533/533 - 404s - loss: 8.0752 - accuracy: 0.0812\n",
            "Epoch 4/50\n",
            "533/533 - 404s - loss: 7.8220 - accuracy: 0.0897\n",
            "Epoch 5/50\n",
            "533/533 - 403s - loss: 7.5649 - accuracy: 0.1001\n",
            "Epoch 6/50\n",
            "\n",
            " 태조 이성계 선대의 가계 목조 이안사가 전주에서 삼척 의주를 거쳐 알동에 정착하다  것을 보내어 , , 그 말하기를 , \n",
            " 임금이 , \n",
            " , \n",
            " 하니 , \n",
            " 하니 , \n",
            " 하니 , \n",
            " 하니 , 임금이 임금이 , \n",
            " 하니 , 임금이 그 말하기를 , \n",
            " 임금이 그 것은 , , 그 계하기를 , \n",
            " 임금이 그 것은 , , 말하기를 , \n",
            " 임금이 말하기를 , \n",
            " 임금이 말하기를 , \n",
            " 임금이 그 것은 , , 그 계하기를 , \n",
            " 임금이 말하기를 , \n",
            " 임금이 말하기를 , \n",
            " 임금이 말하기를 , \n",
            " 임금이 말하기를 , \n",
            " 임금이 그 말하기를 , \n",
            " 임금이 그 것은 , , 그 계하기를 , \n",
            " 임금이\n",
            "\n",
            "533/533 - 407s - loss: 7.2820 - accuracy: 0.1111\n",
            "Epoch 7/50\n",
            "533/533 - 403s - loss: 6.9887 - accuracy: 0.1260\n",
            "Epoch 8/50\n",
            "533/533 - 407s - loss: 6.7167 - accuracy: 0.1425\n",
            "Epoch 9/50\n",
            "533/533 - 407s - loss: 6.4508 - accuracy: 0.1585\n",
            "Epoch 10/50\n",
            "533/533 - 407s - loss: 6.1793 - accuracy: 0.1757\n",
            "Epoch 11/50\n",
            "\n",
            " 태조 이성계 선대의 가계 목조 이안사가 전주에서 삼척 의주를 거쳐 알동에 정착하다  등 감사에게 거느리고 자리 로 설치하고 , 명하여 죄를 거느리고 주었다 그 죄를 거느리고 주고 , 그 죄를 거느리고 주고 , 그 번 것을 의하여 줄 것을 의하여 아뢰라 \n",
            " 하니 , 임금이 말하기를 , \n",
            " 임금이 아뢰기를 , \n",
            " 1 아뢰기를 , \n",
            " 1 말하기를 , \n",
            " 1 말하기를 , 또 말하기를 , 또 말하기를 , 그 관찰사 를 나아가서 , 다만 말하기를 , 또 말하기를 , 또 말하기를 , 청컨대 말하기를 , 청컨대 병조 을 유시 하여 있겠습니까 하였다 청컨대 경 은 그것을 전지 하여 고 하였다 청컨대 경 에서 나아가서 조회를 받다 \n",
            " 상참을 행하고 경연에 나아가다\n",
            "\n",
            "533/533 - 412s - loss: 5.9140 - accuracy: 0.1930\n",
            "Epoch 12/50\n",
            "533/533 - 408s - loss: 5.6426 - accuracy: 0.2100\n",
            "Epoch 13/50\n",
            "533/533 - 408s - loss: 5.3657 - accuracy: 0.2272\n",
            "Epoch 14/50\n",
            "533/533 - 408s - loss: 5.0853 - accuracy: 0.2459\n",
            "Epoch 15/50\n",
            "533/533 - 409s - loss: 4.8137 - accuracy: 0.2643\n",
            "Epoch 16/50\n",
            "\n",
            " 태조 이성계 선대의 가계 목조 이안사가 전주에서 삼척 의주를 거쳐 알동에 정착하다  등 각 번이나 나온 것을 설치하고 , 여러 일을 나누어 일을 나누어 일을 나누어 일을 서로 일을 다 일을 다 주게 되어 말을 가는 지가 아닙니다 다만 유서 를 고쳐 시행하게 하였다 의정부에서 성상의 벌할 성을 정문에 의거하여 아뢰기를 , \n",
            " 의정부에서 아뢰기를 , \n",
            " 의정부에서 전지하기를 , \n",
            " 의정부에서 아뢰기를 , 또 요동 으로 하여금 다 주게 하여 하여금 상서 하지 않을 수 없고 , 경이 경중 을 고쳐 보니 , 오직 척 에 나아가서 시행하게 하소서 \n",
            " 하니 , 임금이 말하기를 , \n",
            " 의정부에서 아뢰기를 , \n",
            " 충청도 관찰사 가 정 가 상언 하여 , 이것은 대답하기를 ,\n",
            "\n",
            "533/533 - 412s - loss: 4.5426 - accuracy: 0.2847\n",
            "Epoch 17/50\n",
            "533/533 - 409s - loss: 4.2897 - accuracy: 0.3052\n",
            "Epoch 18/50\n",
            "533/533 - 407s - loss: 4.0386 - accuracy: 0.3277\n",
            "Epoch 19/50\n",
            "533/533 - 407s - loss: 3.7978 - accuracy: 0.3519\n",
            "Epoch 20/50\n",
            "533/533 - 408s - loss: 3.5688 - accuracy: 0.3763\n",
            "Epoch 21/50\n",
            "\n",
            " 태조 이성계 선대의 가계 목조 이안사가 전주에서 삼척 의주를 거쳐 알동에 정착하다  안에 분수에 어려울 못하여 있게 안에 길을 지나지 못하고 있으니 한 일을 일을 일을 일을 일을 일을 말을 일을 주고 이 말을 주고 한 사람이 서로 명을 알지 않고 혹은 큰 자가 있으면 혹은 받지 못한 데 이르지 않을 수 없으니 , 사간원 않았다 햇무리가 지다 \n",
            " 일본국 관찰사 태수 첨지중추원사 부사 에게 치서 하기를 , \n",
            " 사헌부 에게 불러서 요동 으로 환관 에게 유시 하기를 , \n",
            " 1 관찰사 에게 상서 하여 또한 수령 을 겸하게 합니다 \n",
            " 하였다 예조 에게 유시 하기를 , \n",
            " 일본국 대군 에게 불러서 술을 토물을 여기지 아니하고 모름지기 성품이 쌓아야 영천군 에게 유시하다\n",
            "\n",
            "533/533 - 412s - loss: 3.3401 - accuracy: 0.4051\n",
            "Epoch 22/50\n",
            "533/533 - 407s - loss: 3.1347 - accuracy: 0.4341\n",
            "Epoch 23/50\n",
            "533/533 - 407s - loss: 2.9171 - accuracy: 0.4677\n",
            "Epoch 24/50\n",
            "533/533 - 408s - loss: 2.7581 - accuracy: 0.4929\n",
            "Epoch 25/50\n",
            "533/533 - 407s - loss: 2.6218 - accuracy: 0.5153\n",
            "Epoch 26/50\n",
            "\n",
            " 태조 이성계 선대의 가계 목조 이안사가 전주에서 삼척 의주를 거쳐 알동에 정착하다  수령이 나오지 않은 데에 고쳐서 먹지 못하여 있게 한 것은 각각 1백 일을 각각 한 각각 각각 각각 뜻을 가지고 나누어 주게 하는 자는 사제 으로 청하였다 다행히 임금에게 인친 된 같은 뒤에 모두 크게 아는 일을 자세히 알 수 없으니 , 경이 임금에게 따른 바입니다 그러나 혹은 쳐서 간 곳을 제외하고 혹은 알 것이다 그러나 내가 무슨 공이 아닙니다 그러나 내가 무슨 살고 있습니다 만약 이러한 나라를 보내서 임금에게 알지 못한 것도 실로 자세히 알 수 있습니다 그러나 마땅히 본국 동안 이르렀으니 , 그가 곡식을 내어서 힘써 직접 깊어서 만들게 하였으니 , 경중 으로 보이지 못한 곳을 가두었다 나는\n",
            "\n",
            "533/533 - 411s - loss: 2.3797 - accuracy: 0.5600\n",
            "Epoch 27/50\n",
            "533/533 - 407s - loss: 2.1795 - accuracy: 0.6007\n",
            "Epoch 28/50\n",
            "533/533 - 407s - loss: 1.9823 - accuracy: 0.6402\n",
            "Epoch 29/50\n",
            "533/533 - 406s - loss: 1.8057 - accuracy: 0.6776\n",
            "Epoch 30/50\n",
            "533/533 - 407s - loss: 1.6396 - accuracy: 0.7111\n",
            "Epoch 31/50\n",
            "\n",
            " 태조 이성계 선대의 가계 목조 이안사가 전주에서 삼척 의주를 거쳐 알동에 정착하다  백성들이 폄출 안에 이름을 세우고 안에 이름을 가까이 폐단이 있게 가 각각 각각 1백 뜻을 서로 서로 뜻을 나누어 주었다 혹은 마음이 마음을 기록하여 시종 안에 알고도 정하다 \n",
            " 강무 이지만 원윤 이교 에게는 사객을 기르는 것을 베풀고 , 죄 지 아울러 쳐서 계문 하는 말 의 더불어 장 의 마음이 더불어 장 의 마음이 더불어 장 의 명을 만들어 주소서 , 강원도 육조에서 제사를 머물기를 주라 \n",
            " 하니 , 황화석 양녕 제조 이하는 입시하였다 예조에서 조회를 받고 정사를 행하였다 예조에서 문안하다 \n",
            " 예조에서 계하기를 , \n",
            " 양녕 대군 이하는 내구마 말대로 공문을 마신 점이 마치 국가를 통해 가운데에 곤장\n",
            "\n",
            "533/533 - 409s - loss: 1.4857 - accuracy: 0.7446\n",
            "Epoch 32/50\n",
            "533/533 - 404s - loss: 1.3461 - accuracy: 0.7727\n",
            "Epoch 33/50\n",
            "533/533 - 404s - loss: 1.2123 - accuracy: 0.8009\n",
            "Epoch 34/50\n",
            "533/533 - 405s - loss: 1.1007 - accuracy: 0.8215\n",
            "Epoch 35/50\n",
            "533/533 - 407s - loss: 0.9887 - accuracy: 0.8441\n",
            "Epoch 36/50\n",
            "\n",
            " 태조 이성계 선대의 가계 목조 이안사가 전주에서 삼척 의주를 거쳐 알동에 정착하다  수령이 외방에 지난해의 바람을 정하는 5백 지극한 5백 지극한 5백 가지 것을 나누어 주었다 의 1백 명을 명을 주게 하여 장 사람 인을 제거하는 연후에 의심하고 헐뜯고 만날 만한 말이니 , 모두가 백성의 말에 더 , 마침내 임금의 뜻이 사사로이 아내와 백성들이 올 바 법에 삼가 어김이 다스린 수 심함이 사직을 다스린 때에는 교화를 이룰 것이고 할 것이고 을 바 것도 된 를 만들어 길을 대를 어렵다 하여 , 이 같은 의 의 지 중 의 중에 백성에게 뜻이 있던 곳에 더 정하게 하소서 \n",
            " 하니 , 그대로 따랐다 병조에서 계하기를 , \n",
            " 해청과 생각에는 유상지 에도 상직을 번거로우므로 것과\n",
            "\n",
            "533/533 - 409s - loss: 0.8934 - accuracy: 0.8612\n",
            "Epoch 37/50\n",
            "533/533 - 407s - loss: 0.8018 - accuracy: 0.8788\n",
            "Epoch 38/50\n",
            "533/533 - 410s - loss: 0.7173 - accuracy: 0.8939\n",
            "Epoch 39/50\n",
            "533/533 - 408s - loss: 0.6469 - accuracy: 0.9050\n",
            "Epoch 40/50\n",
            "533/533 - 408s - loss: 0.5871 - accuracy: 0.9148\n",
            "Epoch 41/50\n",
            "\n",
            " 태조 이성계 선대의 가계 목조 이안사가 전주에서 삼척 의주를 거쳐 알동에 정착하다  안으로 이루어진 임명하여 이른 지경에 좋지 못하여 있게 각각 각각 서로 뜻을 서로 뜻을 서로 말을 서로 서로 주게 한 일을 써서 오래 폐단을 알아서 죽으니 , 조석강 을 고사 을 붙여 심한 자의 이른 베는 지경에 들어가서 좇지 않으려 되면 사향 잔을 잡고 돌아온다 내관이 나서 관세 에 고쳐 고쳐 고쳐 있어서 해마다 이렇게 없이 형 사직 요 은 토산 을 받는 못하여 갑자기 호 이다 녹해 1일에 험조 을 선포하는 하면 하물며 신의 생각하기를 신의 생각하기를 왕세자가 생각하기를 왕세자가 내려 받아서 받아서 받아서 받아서 제수한 첩정에 나아가 집사자에게 받아 가지고 다 거느리고 주고 , 여러 번 뜻을 거느리고\n",
            "\n",
            "533/533 - 413s - loss: 0.5249 - accuracy: 0.9257\n",
            "Epoch 42/50\n",
            "533/533 - 408s - loss: 0.4737 - accuracy: 0.9335\n",
            "Epoch 43/50\n",
            "533/533 - 408s - loss: 0.4293 - accuracy: 0.9408\n",
            "Epoch 44/50\n",
            "533/533 - 407s - loss: 0.3848 - accuracy: 0.9478\n",
            "Epoch 45/50\n",
            "533/533 - 406s - loss: 0.3488 - accuracy: 0.9532\n",
            "Epoch 46/50\n",
            "\n",
            " 태조 이성계 선대의 가계 목조 이안사가 전주에서 삼척 의주를 거쳐 알동에 정착하다  관직에 나오지 뒤에는 벼슬을 비로소 소장 안에 비로소 지나치게 둘 를 준 의 1백 상 를 준 의 1백 명을 주게 하는 것이 이미 귀순 하였다 의금부 에서 물러가자 전 호군 호군 궁전 부령 손실이 나아가서 위와 될지라도 소민 에 응한 장수들이 경사 을 기복 하게 합니다 가령 재목의 못하였는데 , 빌건대 고수 초10일에 적당 하게 하소서 \n",
            " 이는 생각하건대 , 대신을 배반하고 상처를 일인데 , 만일 말하지 못한 사람에게 이르지 않아서 위엄을 왔다가 감정 하소서 \n",
            " 1 서연관 환관 1습 에게 띠고서 하게 하였으며 , 그대가 굶주린 공과 을 전하여 있었던 때를 쓴다 고 하였다 경 은 인주 에\n",
            "\n",
            "533/533 - 410s - loss: 0.3198 - accuracy: 0.9570\n",
            "Epoch 47/50\n",
            "533/533 - 405s - loss: 0.2918 - accuracy: 0.9613\n",
            "Epoch 48/50\n",
            "533/533 - 406s - loss: 0.2637 - accuracy: 0.9657\n",
            "Epoch 49/50\n",
            "533/533 - 406s - loss: 0.2412 - accuracy: 0.9688\n",
            "Epoch 50/50\n",
            "\n",
            " 태조 이성계 선대의 가계 목조 이안사가 전주에서 삼척 의주를 거쳐 알동에 정착하다  조정에 조정에 이른 뒤에는 경솔히 소장 있게 있게 한 폐단이 있게 한 폐단이 모두 다 다 전정 의 서로 뜻을 나누어 나누어 나누어 나누어 입고 좌우로 준다 고 하였다 청컨대 조그마한 생각하겠다 \n",
            " 공손히 드러내어 대의에는 불경 온성진 및 우분헌관 대전 을 술을 내려 주고 , 이를 받아 가지고 몸을 올려 의식과 같이 하고 , 곧 아뢰기를 , \n",
            " 찬자가 또 말하기를 , 또 술을 내려서 나와서 매 관사 를 올려 보내고 , 또 아뢰기를 , \n",
            " 그렇다면 특별히 결단하지 조건을 속히 돌아보고 거주하는 무리들은 실상 생업을 명에 주어 한 자는 각각 서로 보내 모두 모두 가서 가서 가서 가서\n",
            "\n",
            "533/533 - 412s - loss: 0.2227 - accuracy: 0.9711\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H8LoG3GoRj8n"
      },
      "source": [
        "test_sentence에 난중일기의 일부분을 주고, 이후 100단어를 출력하도록 한다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bh7EfYFIdeaa",
        "outputId": "0625e700-9273-4d43-cefe-04e534278fe1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 73
        }
      },
      "source": [
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "test_sentence = '동헌에 나가 공무를 본 후 활 십오 순을 쏘았다'\n",
        "\n",
        "next_words = 100\n",
        "for _ in range(next_words):\n",
        "    test_text_X = test_sentence.split(' ')[-seq_length:]\n",
        "    test_text_X = np.array([word2idx[c] if c in word2idx else word2idx['UNK'] for c in test_text_X])\n",
        "    test_text_X = pad_sequences([test_text_X], maxlen=seq_length, padding='pre', value=word2idx['UNK'])\n",
        "    \n",
        "    output_idx = model.predict_classes(test_text_X)\n",
        "    test_sentence += ' ' + idx2word[output_idx[0]]\n",
        "\n",
        "print(test_sentence)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "동헌에 나가 공무를 본 후 활 십오 순을 쏘았다 간격이 대하는 하되 , 약재 는 군 도회소 에 내보이면서 석 인 제읍 인 더불어 영속 이극감 김계손 김계손 행 신종윤 115 밀성군 039 들에게 기르면서 등과 진 정창손 김계손 행 김계손 병조 중추원 이극배 의창 을 이관 겸 의창 579 를 점검하여 채우고 \\? \n",
            " 윤 에 이르렀고 , 대신 에 일일이 베풀고 , 인하여 혹은 상 을 바쳤다 진무 를 변별하는 , 매양 조례의 를 쌓아 상 를 갖추고 1년에 상 를 지키고 하여 항상 실정 에 죽었다 정치를 한다면 한갓 죽음을 군사들 없었던 일입니다 그러나 어찌하여 언관 등으로 율 에 속하게 합니다 그리고 정인지 정식 좌부승지 박강\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}